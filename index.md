# Jaehoon Kim

<style>
.headshot{
  float:right;
  width:clamp(100px,33%,200px);
  margin:0 0 1em 1em;
  aspect-ratio:1/1;
  height:auto;
  object-fit:cover;
}
</style>
<img src="assets/headshot.jpg" alt="Headshot" class="headshot">

- I'm an MS student in AI at Yonsei University, advised by Professor [Dongha Lee](https://donalee.github.io/). Previously, I received my BS in Physics and Computer Science from Sogang University.
- I’m interested in anything that helps thinking machines think deeper. To my current understanding, this includes **instilling reasoning abilities** through supervised fine-tuning on good reasoning traces -- ones that exhibit dense, transparent, and well-structured exploration and exploitation of thoughts -- as well as **eliciting reasoning capacities** hidden within pretrained models and **extending reasoning sequences** to better leverage test-time compute scaling, often drawing inspiration from cognitive processes of the human mind.
- ✨ hydrogen and helium → ⭐ stars → 🌏 earth → 👫 humans → 👣 giants → ⚡🧠 intelligence
- [Email](mailto:jaeh8nkim@yonsei.ac.kr) / [GitHub](https://github.com/jaeh8nkim) / [LinkedIn](https://www.linkedin.com/in/jaeh8nkim)

## Publications
- In Their Own Words: Reasoning Traces Tailored for Small Models Make Them Better Reasoners
  - **Jaehoon Kim**, Kwangwook Seo, Dongha Lee
  - Preprint (arXiv), 2025
  - [paper](https://arxiv.org/abs/2509.22230) / code / dataset

## Presentations
- Recent Advances in Reasoning Research: Instilling Reasoning Abilities with SFT, Eliciting Reasoning Capabilities with RL
  - [slides](https://drive.google.com/file/d/1Sqe_zFRG-iTLHlio5TnSh97dX_3WoWLw/view?usp=drive_link)
